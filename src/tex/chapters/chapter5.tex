\chapter{Training Strategy using Evolutionary Algorithm}
\section{Introduction}
\label{sub:five-intro}
This chapter covers an overview on the contribution of Professor M Jones
in the Axelrod-Python library. Following the presentation of Axelrod-Python
library at PyConUk 2015~\url{http://2016.pyconuk.org/}, he became a member of
the Axelrod-Python team and contributed to the library a new strategy, the
EvolvedLookerUp, which is currently ranked second in the Axlerod-Python tournament.
EvolvedLookerUp is a LookerUp strategy that uses a lookup table generated using an
evolutionary algorithm. The structure of the strategy and the evolution algorithm
will be covered in the following sections.

Furthermore, the method developed by M Jones to train the EvolvedLookerUp
will be redeveloped and used. Making it possible to train a new strategy
by competing against random opponents into various spatial tournaments.

%A brief introduction to the genetic algorithm will also be covered.

\section{The Lookup Evolve Algorithm}
\label{sub:lookup-evolve-algorithm}
As stated in ~\autoref{sub:five-intro}, the LookerUp strategies uses a lookup to
determine the strategy's next move. In this section, the lookup table, as well as
the LookerUp strategies are explained. Additionally, the mechanism used for the
maximization of these strategies performance will be discussed.

\subsection{The Lookup Table}
The strategies of the Axelrod-Python library have access to their own history,
through the \texttt{self.history} variable and the opponent's history though
\texttt{opponent.history} variable. Many strategies choose their actions based
on what happened on previous turns\footnote{Only two actions are possible in the
IPD; to either Cooperate(C) or to Defect(D).}. This rule, of determining once actions
based on a history can be think of as a lookup table.
In Jones work three different histories are taken into account:

\begin{itemize}
  \item the opponents two starting actions
  \item the opponent's two recent actions
  \item and the recent actions of the strategy.
\end{itemize}

Using Python's dictionaries the histories can be considered as keys and
the action as the values. Thus, the keys are a 3-tuples consisting of the opponent's
starting actions, the opponent's recent actions, and the strategy's recent actions.
The lookup table in total contains 64 different keys and a key/value pairs example
is illustrated in Listing~\ref{lst:lookup-table}.

\begin{listing}[H]
\usemintedstyle{tango}
\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
bgcolor=LightGray,
fontsize=\footnotesize,
linenos
]
{python}
lookup_table = {
    ...
    ('CC', 'CC', 'DD') : 'D',
    ('DD', 'CC', 'DD') : 'C',
    ...
}
\end{minted}
\caption{Example of lookup table}
\label{lst:lookup-table}
\end{listing}

The lookup table corresponds to a guideline which the strategy determines it's following action.
A class for generating a strategy object, which  will take into account a lookup tables,
for playing the IPD game is described in the following subsection.

\subsection{The LookerUp class}

The LookerUp class, is generating a object for a given lookup table.
The source code of the class, as written by M Jones, is illustrated in the
Listing~\ref{lst:lookerup}. As shown, the strategy taken as an argument
a lookup table and therefore plays by following these regulations:
\begin{itemize}
  \item If history is smaller than 2, then  always cooperate
  \item if history is greater than 2, create key
  \item check lookup table for corresponding key and value
  \item return value as action
\end{itemize}

\begin{listing}[H]
\usemintedstyle{tango}
\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
bgcolor=LightBlue,
fontsize=\footnotesize,
linenos
]
{python}
class LookerUp(Player):

    def __init__(self, lookup_table):
        self.lookup_table = lookup_table


    def strategy(self, opponent):
        # If there isn't enough history to lookup an action, cooperate.
        if len(self.history) < 2:
            return C

        # Get my own last two actions
        my_history = ''.join(self.history[-2:])

        # Do the same for the opponent.
        opponent_history = ''.join(opponent.history[-2:])

        # Get the opponents first two actions.
        opponent_start = ''.join(opponent.history[:2])

        # Put these three strings together in a tuple.
        key = (opponent_start, my_history, opponent_history)

        # Look up the action associated with that tuple in the lookup table.
        action = self.lookup_table[key]

        return action
\end{minted}
\caption{The LookerUp class source code}
\label{lst:lookerup}
\end{listing}

The class is used to test the performance of the table. EvolverLookerup, is a
later version of LookerUp, the difference is that EvolverLookerUp uses a satisfactory
table, crafted by using an evolutionary algorithm. The process will be described
in the following subsection.

\subsection{Evolutionary Algorithm}
\label{sub:evolutionary-algorithm}
The performance of a lookup table is measured as the average score the lookup
strategy achieves in a round robin tournament against all strategies in the
Axelrod-Python library. Though various optimization processes could have been
used for the maximization of the objective function,
the genetic algorithm was preferred. Genetic algorithm, is a commonly used adaptive
algorithm for solving practical problems. An introduction in the genetic algorithm
has been covered by M Mitchell~\cite{Mitchell1998}, and along various applications~\cite{Chang1994}
it has been used in the field of Game Theory as well~\cite{Ismail2007}.

The lookerup evolve algorithm, which is the algorithm that tries to maximize
the performance using the genetic algorithm is described by the flow chart in
Figure~\ref{fig:flookerup-evolve-flow}. The algorithm starts off by creating
\(n\) number of random tables. These tables are then passed in genetic algorithm
as the current tables.
Once the genetic algorithm kicks off children are reproduced for every single pair
of parents. The reproduction process included random crossovers as well as a
mutation rate \(u\). Subsequently, the population is defined as the joint of
parents and children.

Each member of the population has to go through the scoring process. A different
object of the LookerUp strategy is created for each of the lookup tables that
exist in the population, and each object participates to a round robin tournament.
Thereupon, the population is being sorted based on the average score per turn.
Only the top \(b\) individuals are then selected to continue to the next generation.
This is repeated until the number of generations reach the upper bound \(g\).

The default values of the parameters in the lookerup evolve algorithm are as
follow:
\begin{itemize}
  \item \(n\) default value is equal to 5
  \item \(u\) default value is equal to 0.1
  \item \(b\) default value is equal to 10
  \item \(g\) default value is equal to 100
\end{itemize}

\begin{figure}[!hbtp]
		\input{chapters/lookerup.tex}
		\caption{Lookerup Evolve Algorithm Flow Chart}
  \label{fig:flookerup-evolve-flow}
\end{figure}

In this section an overview of M Jones works was implemented. The full version
of the LookUpEvolver, his implementation of the genetic algorithm and the lookerup evolve
algorithm can be found here:\url{https://github.com/mojones/axelrod-evolver}.
In the upcoming section how the lookerup evolve algorithm was altered and used
for the spatial tournaments is being discussed.

\section{The Spatial Lookup Evolve Algorithm}

Inspired by the work done by M Jones, as was described in ~\autoref{sub:lookup-evolve-algorithm},
the lookup evolve algorithm will be used to train a new strategy. The goal is to
train a strategy, which will have an overall 'good' performance for any given
spatial tournament.

Large parts of the lookup evolve algorithm code that have already written
can be used. The main difference in this new spatial algorithm is the objective
function of the genetic algorithm.
\subsection{Objective Function}

In the approach of the spatial lookup evolve algorithm, one of the main differences
occurs in the objective function in the scoring process. Instead of the average
score in a round robin tournament, the median normalizes rank, as introduced
in ~\autoref{chap:Four}, for a spatial tournament is taken into account.

Using a similar approach to the one described in ~\autoref{chap:Four}, the objective
function will be the median rank a strategy achieved, after participating in \(p\)
random spatial tournaments of random different topologies. The tournament sizes
as well as the players participating in these tournaments are completely random.
The topologies can be that of a Watts Strogatz, a Erd\"{o}s
R\'{e}nyi or a complete graph. In Figure~\ref{fig:objective}, a flow chart
illustrates the idea of how this was implemented. Before and after the scoring
process the nodes are the same as have been seen in Figure~\ref{fig:flookerup-evolve-flow}.

\begin{figure}[!hbtp]
		\input{chapters/objective.tex}
		\caption{Scoring Process for Spatial Lookup Evolve Algorithm}
  \label{fig:objective}
\end{figure}


Furthermore, for every given generation the current tables are being re scored.
Due the randomness that the scoring process includes different scores for the
same lookup tables could occurs. Thus, the objective functions stops being
deterministic.

In addition, two different cases will be studied based on the strategies list.

\subsubsection{Non Deterministic}

The difference in these two cases occurs in the population of the strategies.
More specifically, for the non deterministic case
the population of strategies, from where the sample for participants for
the spatial games is being subtract, contains all 132 strategies of the
Axlerod-Python. The sample for each repetition \(p\) is randomly picked. For the
non deterministic case two sample sizes have been used. One from
15 to 50 players and the other one from 5 to 15 strategies.

\subsubsection{Deterministic}

For the deterministic case the population will contain only
the deterministic strategies of the Axelrod-Python library. The library provides
easy access to them and they have been identified as the following ten strategies:
\begin{itemize}
   \item Alternator
   \item Anti Tit For Tat
   \item Bully
   \item Cooperator
   \item Cycler DC
   \item Defector
   \item Suspicious Tit For Tat
   \item Tit For Tat
   \item Win-Shift Lose-Stay
   \item Win-Stay Lose-Shift
\end{itemize}

Thus the sample size this time will range between 5 to 10. Both of these
objectives are used for individual runs of the spatial lookup evolve algorithm.

\subsection{Parameters}

One can notice by the default values of the evolutionary algorithm parameters,
described in \autoref{sub:evolutionary-algorithm}, in each generation
144 lookup tables needed to be scored. Considering that each lookup table needs
to participate in \(p\) different spatial tournaments the time to implement
each generation is growing massively. The spatial lookup evolve algorithm
has been compiled in Raven, even so it still required a lot of time. Due to time
constraints of this dissertation these values had to altered. The new values
that have been used, alongside the values of the new parameters introduced
by the spatial version of the algorithm are listed here:
\begin{itemize}
    \item \(n\) default value is equal to 2
    \item \(u\) default value is equal to 0.1
    \item \(b\) default value is equal to 2
    \item \(g\) default value is equal to 5000
\end{itemize}

By setting \(n\) to 2 and by keeping only the 2 top of each generations only
20 lookup tables are being scored for each generation. Furthermore, the generations
have been set to 5000 though the results obtained and introduced in the following
subsection have been from earlier generations. The time limit for each algorithm
was set at 70 hours. The entire spatial scoring structure that
has been explained throughly during this subsection is illustrated in Figure~\ref{fig:spatial-evolve}.
Moreover, the source code for implementing the spatial version of the algorithm
are found here: \url{https://github.com/Nikoleta-v3/axelrod-evolver/tree/general-spatial}.

\begin{figure}[H]
		\input{chapters/spatialevolve.tex}
		\caption{Complete Scoring Process for Spatial Lookup Evolve Algorithm}
  \label{fig:spatial-evolve}
\end{figure}

\section{Results}
In this sections the results of the spatial lookup evolve algorithm are briefly
presented. The results are divided into three categories based on the strategies
population and on the sample size. For each, the keys of the lookup table,
the lowest median normalized ranks and the generation it was achieved are given
in Table~\ref{results-genet}.

For the deterministic case the best strategy, with a score of 0.77 median normalized
rank, was achieved at the 319\nth generation. For the same generation the mean score
has been 0.57 with a standard deviation of 0.20. For the non deterministic case
and a sample size ranging from 5 to 15 the best lookup table has been achieved at
the 201\st generation. The best score was estimated at 0.769, with a mean population
of 0.36 and a standard deviation of 0.23. Finally, for the non deterministic with
a range of sample size between 15 and 50, the lowest median rank has been 0.68.
Thus, for a non deterministic case the specific lookup table generates
the best performed strategy so far.

\begin{table}[H]
\centering
\begin{adjustbox}{width=0.9\textwidth}
\small
\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{4}{|c|}{Results}                                                                                                                                                                                              \\ \hline
                                       & lookup values      & generation                                                                                         & score                                                   \\ \hline
  Deterministic                         & \begin{tabular}[c]{@{}l@{}}DDDDCDDDDCDCDCDDDCDCCDDCDDCCCDDC\\ CDCDCDCCDDCCCCDCDCCCCCCCDDCCDCCD\end{tabular} & 319  & 0.777778                                                     \\ \hline
  \begin{tabular}[c]{@{}l@{}}Non-deterministic\\ sample size(5-15)\end{tabular} & \begin{tabular}[c]{@{}l@{}}CDDCCDDDCDCDCDDDCDCDCCCCDCDDDCCC\\ DCDDDCDCDDCCDCDCCCDDCDDCCCDCCDDC\end{tabular} & 201 & 0.769231               \\ \hline
  \begin{tabular}[c]{@{}l@{}}Non-deterministic\\ sample size(15-50)\end{tabular}& \begin{tabular}[c]{@{}l@{}}DDDCCDDCCCCCDCCDDDCCCCCDDCCDDCDCC\\ CDDCDCDCDDCCCDCCCDCCCDDCDDDDDCD\end{tabular} & 148 & 0.6875                  \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Results for Spatial Lookup Evolve Algorithm for Median Normalized Rank}
\label{results-genet}
\end{table}

For comparison reasons an extra algorithm has been performed. This time the
objective function has been measured as the minimum normalized score and was carried
out for only the non deterministic case.The results
that were generated from this run are given by the Table~\ref{results-min-geten}.
The overall results have been lower than before. The finest score has been achieved for
a sample size of 15 to 50 and returned an minimum normalized score of 0.478.

\begin{table}[H]
\centering
\begin{adjustbox}{width=0.8\textwidth}
\small
\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{4}{|c|}{Results}                                                                                                                                                                                             \\ \hline
                                     & lookup values  & generation   & score                                                                                                                                              \\ \hline
\begin{tabular}[c]{@{}l@{}}Non-deterministic\\ sample size(5-15)\end{tabular}   & \begin{tabular}[c]{@{}l@{}}DDDDDCCDCDCDDCCDCCDDCCCDDCDCDCDC\\ CCCCCCDCDCDDDDCCDCDCDDDDDCDDDDCD\end{tabular} & 47 & 0.692308                  \\ \hline
                                     & \begin{tabular}[c]{@{}l@{}}CCDCDCDDDCCDDCDCDCDDCCDCDDCDDDCD\\ CDCCDCCDDDDDCCCDCCDDDCDCDDDCCCDD\end{tabular}  & 13 & 0.692308                                                             \\ \hline
                                     & \begin{tabular}[c]{@{}l@{}}DCCCDDCCCDDCDDDDDDCDDCCDCCDDCDDD\\ DDDDCDDDDCCDDDDCCDCCCDDDCCCCCCCC\end{tabular}  & 8 & 0.692308                                                             \\ \hline
\begin{tabular}[c]{@{}l@{}}Non-deterministic\\ sample size(15-50)\end{tabular}& \begin{tabular}[c]{@{}l@{}}CDCCDDCDDDCCCDDDDCDCDCCDDCDCCDDD\\ DCDCCDCCCDDDCDDCDCDCDDCCCCCCDDDC\end{tabular} & 49 & 0.478261                     \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Results for Spatial Lookup Evolve Algorithm for Minimum Normalized Rank}
\label{results-min-geten}
\end{table}

In this section the lookup tables that have been produced by the spatial lookup
evolve algorithm from each case that has been implemented were presented and discussed.
The finest lookup table for measuring the median normalized rank has been estimated
at 0.68. Furthermore, a new case of objective function has also been implemented
for comparison reasons. Additionally, in the following section the algorithm has
been perform for each of the networks individually.

\section{Further Results}

In this section some additional results of the spatial lookup evolve algorithm
are discussed. In the previous section the networks used in the scoring process
have been randomly picked between small world, random and complete networks.
In this section the algorithm has been implemented each of network and their
individual results are studied. This was implemented mainly for further results and
a possible identification of a well perform strategy for an individual topology.
Table~\ref{deter-indiv} and Table~\ref{no-deter-indiv} summarize the results.

For the deterministic case where the topology of the spatial tournaments has been
a Watts Strogatz networks, the first rate lookup table achieved a median normalized
score of 0, in the 635\nth generation. Moreover, for the Erd\"\{o\}sR\'\{e\}nyi
topology the finest lookup table has a score of 0.5 in the 1399\nth generation, similar
to the complete on where the lowest rank achieved has been 0.555556.

\begin{table}[H]
\centering
\begin{adjustbox}{width=0.8\textwidth}
\small
\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{4}{|c|}{\textbf{Deterministic Results}}                                                                                                         \\ \hline
                       & lookup                                                                                                      & generation & score    \\ \hline
Watts Strogatz         & \begin{tabular}[c]{@{}l@{}}CDCCCDDDCCCDCCCDDDCDCDCCDCCCDCDCC\\ DCCDDDDCCCDDCDDCDDDDDDCCDDDDCDC\end{tabular} & 635        & 0.00     \\ \hline
Erd\"\{o\}sR\'\{e\}nyi & \begin{tabular}[c]{@{}l@{}}CCCDDCCCDCDCCCCDDCCCCDDDDCCDCDCDD\\ DDCCCCCDDCCCDDCDCCDCDCDDDCDCDCC\end{tabular} & 1399       & 0.5      \\ \hline
Complete               & \begin{tabular}[c]{@{}l@{}}DDCCCCDDDDDDCCDCCDDDCDDDCCDDDDCC\\ DCCDDCDCCCCDCCDDDCCDCCDCDCCCCCCC\end{tabular} & 1299       & 0.555556 \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Results of Deterministic Players for Watts Strogatz, Erd\"\{o\}sR\'\{e\}nyi and Complete Networks}
\label{deter-indiv}
\end{table}

The achievement in this section has been in the deterministic players case where
a median rank of 0 has been attained. This give evidence that at least one of
networks has this capability. Thus, further research is inspired to be conduced.
